/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package adventureworks
package public
package only_pk_columns

import typo.dsl.DeleteBuilder
import typo.dsl.SelectBuilder
import typo.dsl.SelectBuilderSql
import typo.dsl.UpdateBuilder
import zio.ZIO
import zio.jdbc.SqlFragment.Segment
import zio.jdbc.SqlFragment.Setter
import zio.jdbc.UpdateResult
import zio.jdbc.ZConnection
import zio.jdbc.sqlInterpolator
import zio.stream.ZStream

class OnlyPkColumnsRepoImpl extends OnlyPkColumnsRepo {
  override def delete: DeleteBuilder[OnlyPkColumnsFields, OnlyPkColumnsRow] = {
    DeleteBuilder(""""public"."only_pk_columns"""", OnlyPkColumnsFields.structure)
  }
  override def deleteById(compositeId: OnlyPkColumnsId): ZIO[ZConnection, Throwable, Boolean] = {
    sql"""delete from "public"."only_pk_columns" where "key_column_1" = ${Segment.paramSegment(compositeId.keyColumn1)(Setter.stringSetter)} AND "key_column_2" = ${Segment.paramSegment(compositeId.keyColumn2)(Setter.intSetter)}""".delete.map(_ > 0)
  }
  override def deleteByIds(compositeIds: Array[OnlyPkColumnsId]): ZIO[ZConnection, Throwable, Long] = {
    val keyColumn1 = compositeIds.map(_.keyColumn1)
    val keyColumn2 = compositeIds.map(_.keyColumn2)
    sql"""delete
          from "public"."only_pk_columns"
          where ("key_column_1", "key_column_2")
          in (select unnest(${keyColumn1}), unnest(${keyColumn2}))
       """.delete
    
  }
  override def insert(unsaved: OnlyPkColumnsRow): ZIO[ZConnection, Throwable, OnlyPkColumnsRow] = {
    sql"""insert into "public"."only_pk_columns"("key_column_1", "key_column_2")
          values (${Segment.paramSegment(unsaved.keyColumn1)(Setter.stringSetter)}, ${Segment.paramSegment(unsaved.keyColumn2)(Setter.intSetter)}::int4)
          returning "key_column_1", "key_column_2"
       """.insertReturning(using OnlyPkColumnsRow.jdbcDecoder).map(_.updatedKeys.head)
  }
  override def insertStreaming(unsaved: ZStream[ZConnection, Throwable, OnlyPkColumnsRow], batchSize: Int = 10000): ZIO[ZConnection, Throwable, Long] = {
    streamingInsert(s"""COPY "public"."only_pk_columns"("key_column_1", "key_column_2") FROM STDIN""", batchSize, unsaved)(OnlyPkColumnsRow.text)
  }
  override def select: SelectBuilder[OnlyPkColumnsFields, OnlyPkColumnsRow] = {
    SelectBuilderSql(""""public"."only_pk_columns"""", OnlyPkColumnsFields.structure, OnlyPkColumnsRow.jdbcDecoder)
  }
  override def selectAll: ZStream[ZConnection, Throwable, OnlyPkColumnsRow] = {
    sql"""select "key_column_1", "key_column_2" from "public"."only_pk_columns"""".query(using OnlyPkColumnsRow.jdbcDecoder).selectStream()
  }
  override def selectById(compositeId: OnlyPkColumnsId): ZIO[ZConnection, Throwable, Option[OnlyPkColumnsRow]] = {
    sql"""select "key_column_1", "key_column_2" from "public"."only_pk_columns" where "key_column_1" = ${Segment.paramSegment(compositeId.keyColumn1)(Setter.stringSetter)} AND "key_column_2" = ${Segment.paramSegment(compositeId.keyColumn2)(Setter.intSetter)}""".query(using OnlyPkColumnsRow.jdbcDecoder).selectOne
  }
  override def selectByIds(compositeIds: Array[OnlyPkColumnsId]): ZStream[ZConnection, Throwable, OnlyPkColumnsRow] = {
    val keyColumn1 = compositeIds.map(_.keyColumn1)
    val keyColumn2 = compositeIds.map(_.keyColumn2)
    sql"""select "key_column_1", "key_column_2"
          from "public"."only_pk_columns"
          where ("key_column_1", "key_column_2")
          in (select unnest(${keyColumn1}), unnest(${keyColumn2}))
       """.query(using OnlyPkColumnsRow.jdbcDecoder).selectStream()
    
  }
  override def selectByIdsTracked(compositeIds: Array[OnlyPkColumnsId]): ZIO[ZConnection, Throwable, Map[OnlyPkColumnsId, OnlyPkColumnsRow]] = {
    selectByIds(compositeIds).runCollect.map { rows =>
      val byId = rows.view.map(x => (x.compositeId, x)).toMap
      compositeIds.view.flatMap(id => byId.get(id).map(x => (id, x))).toMap
    }
  }
  override def update: UpdateBuilder[OnlyPkColumnsFields, OnlyPkColumnsRow] = {
    UpdateBuilder(""""public"."only_pk_columns"""", OnlyPkColumnsFields.structure, OnlyPkColumnsRow.jdbcDecoder)
  }
  override def upsert(unsaved: OnlyPkColumnsRow): ZIO[ZConnection, Throwable, UpdateResult[OnlyPkColumnsRow]] = {
    sql"""insert into "public"."only_pk_columns"("key_column_1", "key_column_2")
          values (
            ${Segment.paramSegment(unsaved.keyColumn1)(Setter.stringSetter)},
            ${Segment.paramSegment(unsaved.keyColumn2)(Setter.intSetter)}::int4
          )
          on conflict ("key_column_1", "key_column_2")
          do update set "key_column_1" = EXCLUDED."key_column_1"
          returning "key_column_1", "key_column_2"""".insertReturning(using OnlyPkColumnsRow.jdbcDecoder)
  }
  /* NOTE: this functionality is not safe if you use auto-commit mode! it runs 3 SQL statements */
  override def upsertStreaming(unsaved: ZStream[ZConnection, Throwable, OnlyPkColumnsRow], batchSize: Int = 10000): ZIO[ZConnection, Throwable, Long] = {
    val created = sql"""create temporary table only_pk_columns_TEMP (like "public"."only_pk_columns") on commit drop""".execute
    val copied = streamingInsert(s"""copy only_pk_columns_TEMP("key_column_1", "key_column_2") from stdin""", batchSize, unsaved)(OnlyPkColumnsRow.text)
    val merged = sql"""insert into "public"."only_pk_columns"("key_column_1", "key_column_2")
                       select * from only_pk_columns_TEMP
                       on conflict ("key_column_1", "key_column_2")
                       do nothing
                       ;
                       drop table only_pk_columns_TEMP;""".update
    created *> copied *> merged
  }
}
