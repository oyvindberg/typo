/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package adventureworks
package pg_catalog
package pg_stat_progress_cluster

import java.sql.ResultSet
import zio.jdbc.JdbcDecoder
import zio.json.JsonDecoder
import zio.json.JsonEncoder
import zio.json.ast.Json
import zio.json.internal.Write

case class PgStatProgressClusterViewRow(
  pid: /* nullability unknown */ Option[Int],
  datid: /* nullability unknown */ Option[/* oid */ Long],
  /** Points to [[pg_database.PgDatabaseRow.datname]] */
  datname: Option[String],
  relid: /* nullability unknown */ Option[/* oid */ Long],
  command: /* nullability unknown */ Option[String],
  phase: /* nullability unknown */ Option[String],
  clusterIndexRelid: /* nullability unknown */ Option[/* oid */ Long],
  heapTuplesScanned: /* nullability unknown */ Option[Long],
  heapTuplesWritten: /* nullability unknown */ Option[Long],
  heapBlksTotal: /* nullability unknown */ Option[Long],
  heapBlksScanned: /* nullability unknown */ Option[Long],
  indexRebuildCount: /* nullability unknown */ Option[Long]
)

object PgStatProgressClusterViewRow {
  implicit lazy val jdbcDecoder: JdbcDecoder[PgStatProgressClusterViewRow] = new JdbcDecoder[PgStatProgressClusterViewRow] {
    override def unsafeDecode(columIndex: Int, rs: ResultSet): (Int, PgStatProgressClusterViewRow) =
      columIndex + 11 ->
        PgStatProgressClusterViewRow(
          pid = JdbcDecoder.optionDecoder(JdbcDecoder.intDecoder).unsafeDecode(columIndex + 0, rs)._2,
          datid = JdbcDecoder.optionDecoder(JdbcDecoder.longDecoder).unsafeDecode(columIndex + 1, rs)._2,
          datname = JdbcDecoder.optionDecoder(JdbcDecoder.stringDecoder).unsafeDecode(columIndex + 2, rs)._2,
          relid = JdbcDecoder.optionDecoder(JdbcDecoder.longDecoder).unsafeDecode(columIndex + 3, rs)._2,
          command = JdbcDecoder.optionDecoder(JdbcDecoder.stringDecoder).unsafeDecode(columIndex + 4, rs)._2,
          phase = JdbcDecoder.optionDecoder(JdbcDecoder.stringDecoder).unsafeDecode(columIndex + 5, rs)._2,
          clusterIndexRelid = JdbcDecoder.optionDecoder(JdbcDecoder.longDecoder).unsafeDecode(columIndex + 6, rs)._2,
          heapTuplesScanned = JdbcDecoder.optionDecoder(JdbcDecoder.longDecoder).unsafeDecode(columIndex + 7, rs)._2,
          heapTuplesWritten = JdbcDecoder.optionDecoder(JdbcDecoder.longDecoder).unsafeDecode(columIndex + 8, rs)._2,
          heapBlksTotal = JdbcDecoder.optionDecoder(JdbcDecoder.longDecoder).unsafeDecode(columIndex + 9, rs)._2,
          heapBlksScanned = JdbcDecoder.optionDecoder(JdbcDecoder.longDecoder).unsafeDecode(columIndex + 10, rs)._2,
          indexRebuildCount = JdbcDecoder.optionDecoder(JdbcDecoder.longDecoder).unsafeDecode(columIndex + 11, rs)._2
        )
  }
  implicit lazy val jsonDecoder: JsonDecoder[PgStatProgressClusterViewRow] = JsonDecoder[Json.Obj].mapOrFail { jsonObj =>
    val pid = jsonObj.get("pid").fold[Either[String, Option[Int]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.int)))
    val datid = jsonObj.get("datid").fold[Either[String, Option[Long]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.long)))
    val datname = jsonObj.get("datname").fold[Either[String, Option[String]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.string)))
    val relid = jsonObj.get("relid").fold[Either[String, Option[Long]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.long)))
    val command = jsonObj.get("command").fold[Either[String, Option[String]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.string)))
    val phase = jsonObj.get("phase").fold[Either[String, Option[String]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.string)))
    val clusterIndexRelid = jsonObj.get("cluster_index_relid").fold[Either[String, Option[Long]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.long)))
    val heapTuplesScanned = jsonObj.get("heap_tuples_scanned").fold[Either[String, Option[Long]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.long)))
    val heapTuplesWritten = jsonObj.get("heap_tuples_written").fold[Either[String, Option[Long]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.long)))
    val heapBlksTotal = jsonObj.get("heap_blks_total").fold[Either[String, Option[Long]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.long)))
    val heapBlksScanned = jsonObj.get("heap_blks_scanned").fold[Either[String, Option[Long]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.long)))
    val indexRebuildCount = jsonObj.get("index_rebuild_count").fold[Either[String, Option[Long]]](Right(None))(_.as(JsonDecoder.option(JsonDecoder.long)))
    if (pid.isRight && datid.isRight && datname.isRight && relid.isRight && command.isRight && phase.isRight && clusterIndexRelid.isRight && heapTuplesScanned.isRight && heapTuplesWritten.isRight && heapBlksTotal.isRight && heapBlksScanned.isRight && indexRebuildCount.isRight)
      Right(PgStatProgressClusterViewRow(pid = pid.toOption.get, datid = datid.toOption.get, datname = datname.toOption.get, relid = relid.toOption.get, command = command.toOption.get, phase = phase.toOption.get, clusterIndexRelid = clusterIndexRelid.toOption.get, heapTuplesScanned = heapTuplesScanned.toOption.get, heapTuplesWritten = heapTuplesWritten.toOption.get, heapBlksTotal = heapBlksTotal.toOption.get, heapBlksScanned = heapBlksScanned.toOption.get, indexRebuildCount = indexRebuildCount.toOption.get))
    else Left(List[Either[String, Any]](pid, datid, datname, relid, command, phase, clusterIndexRelid, heapTuplesScanned, heapTuplesWritten, heapBlksTotal, heapBlksScanned, indexRebuildCount).flatMap(_.left.toOption).mkString(", "))
  }
  implicit lazy val jsonEncoder: JsonEncoder[PgStatProgressClusterViewRow] = new JsonEncoder[PgStatProgressClusterViewRow] {
    override def unsafeEncode(a: PgStatProgressClusterViewRow, indent: Option[Int], out: Write): Unit = {
      out.write("{")
      out.write(""""pid":""")
      JsonEncoder.option(JsonEncoder.int).unsafeEncode(a.pid, indent, out)
      out.write(",")
      out.write(""""datid":""")
      JsonEncoder.option(JsonEncoder.long).unsafeEncode(a.datid, indent, out)
      out.write(",")
      out.write(""""datname":""")
      JsonEncoder.option(JsonEncoder.string).unsafeEncode(a.datname, indent, out)
      out.write(",")
      out.write(""""relid":""")
      JsonEncoder.option(JsonEncoder.long).unsafeEncode(a.relid, indent, out)
      out.write(",")
      out.write(""""command":""")
      JsonEncoder.option(JsonEncoder.string).unsafeEncode(a.command, indent, out)
      out.write(",")
      out.write(""""phase":""")
      JsonEncoder.option(JsonEncoder.string).unsafeEncode(a.phase, indent, out)
      out.write(",")
      out.write(""""cluster_index_relid":""")
      JsonEncoder.option(JsonEncoder.long).unsafeEncode(a.clusterIndexRelid, indent, out)
      out.write(",")
      out.write(""""heap_tuples_scanned":""")
      JsonEncoder.option(JsonEncoder.long).unsafeEncode(a.heapTuplesScanned, indent, out)
      out.write(",")
      out.write(""""heap_tuples_written":""")
      JsonEncoder.option(JsonEncoder.long).unsafeEncode(a.heapTuplesWritten, indent, out)
      out.write(",")
      out.write(""""heap_blks_total":""")
      JsonEncoder.option(JsonEncoder.long).unsafeEncode(a.heapBlksTotal, indent, out)
      out.write(",")
      out.write(""""heap_blks_scanned":""")
      JsonEncoder.option(JsonEncoder.long).unsafeEncode(a.heapBlksScanned, indent, out)
      out.write(",")
      out.write(""""index_rebuild_count":""")
      JsonEncoder.option(JsonEncoder.long).unsafeEncode(a.indexRebuildCount, indent, out)
      out.write("}")
    }
  }
}
