/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package adventureworks
package frontpage
package employee

import adventureworks.customtypes.Defaulted
import adventureworks.frontpage.person.PersonId
import cats.instances.list.catsStdInstancesForList
import doobie.free.connection.ConnectionIO
import doobie.postgres.syntax.FragmentOps
import doobie.syntax.SqlInterpolator.SingleFragment.fromWrite
import doobie.syntax.string.toSqlInterpolator
import doobie.util.Write
import doobie.util.fragment.Fragment
import doobie.util.meta.Meta
import doobie.util.update.Update
import fs2.Stream
import typo.dsl.DeleteBuilder
import typo.dsl.SelectBuilder
import typo.dsl.SelectBuilderSql
import typo.dsl.UpdateBuilder

class EmployeeRepoImpl extends EmployeeRepo {
  override def delete: DeleteBuilder[EmployeeFields, EmployeeRow] = {
    DeleteBuilder(""""frontpage"."employee"""", EmployeeFields.structure)
  }
  override def deleteById(id: EmployeeId): ConnectionIO[Boolean] = {
    sql"""delete from "frontpage"."employee" where "id" = ${fromWrite(id)(new Write.Single(EmployeeId.put))}""".update.run.map(_ > 0)
  }
  override def deleteByIds(ids: Array[EmployeeId]): ConnectionIO[Int] = {
    sql"""delete from "frontpage"."employee" where "id" = ANY(${ids})""".update.run
  }
  override def insert(unsaved: EmployeeRow): ConnectionIO[EmployeeRow] = {
    sql"""insert into "frontpage"."employee"("id", "person_id", "salary")
          values (${fromWrite(unsaved.id)(new Write.Single(EmployeeId.put))}::uuid, ${fromWrite(unsaved.personId)(new Write.Single(PersonId.put))}::uuid, ${fromWrite(unsaved.salary)(new Write.SingleOpt(Meta.ScalaBigDecimalMeta.put))}::numeric)
          returning "id", "person_id", "salary"
       """.query(using EmployeeRow.read).unique
  }
  override def insert(unsaved: EmployeeRowUnsaved): ConnectionIO[EmployeeRow] = {
    val fs = List(
      Some((Fragment.const0(s""""person_id""""), fr"${fromWrite(unsaved.personId)(new Write.Single(PersonId.put))}::uuid")),
      Some((Fragment.const0(s""""salary""""), fr"${fromWrite(unsaved.salary)(new Write.SingleOpt(Meta.ScalaBigDecimalMeta.put))}::numeric")),
      unsaved.id match {
        case Defaulted.UseDefault => None
        case Defaulted.Provided(value) => Some((Fragment.const0(s""""id""""), fr"${fromWrite(value: EmployeeId)(new Write.Single(EmployeeId.put))}::uuid"))
      }
    ).flatten
    
    val q = if (fs.isEmpty) {
      sql"""insert into "frontpage"."employee" default values
            returning "id", "person_id", "salary"
         """
    } else {
      val CommaSeparate = Fragment.FragmentMonoid.intercalate(fr", ")
      sql"""insert into "frontpage"."employee"(${CommaSeparate.combineAllOption(fs.map { case (n, _) => n }).get})
            values (${CommaSeparate.combineAllOption(fs.map { case (_, f) => f }).get})
            returning "id", "person_id", "salary"
         """
    }
    q.query(using EmployeeRow.read).unique
    
  }
  override def insertStreaming(unsaved: Stream[ConnectionIO, EmployeeRow], batchSize: Int = 10000): ConnectionIO[Long] = {
    new FragmentOps(sql"""COPY "frontpage"."employee"("id", "person_id", "salary") FROM STDIN""").copyIn(unsaved, batchSize)(using EmployeeRow.text)
  }
  /* NOTE: this functionality requires PostgreSQL 16 or later! */
  override def insertUnsavedStreaming(unsaved: Stream[ConnectionIO, EmployeeRowUnsaved], batchSize: Int = 10000): ConnectionIO[Long] = {
    new FragmentOps(sql"""COPY "frontpage"."employee"("person_id", "salary", "id") FROM STDIN (DEFAULT '__DEFAULT_VALUE__')""").copyIn(unsaved, batchSize)(using EmployeeRowUnsaved.text)
  }
  override def select: SelectBuilder[EmployeeFields, EmployeeRow] = {
    SelectBuilderSql(""""frontpage"."employee"""", EmployeeFields.structure, EmployeeRow.read)
  }
  override def selectAll: Stream[ConnectionIO, EmployeeRow] = {
    sql"""select "id", "person_id", "salary" from "frontpage"."employee"""".query(using EmployeeRow.read).stream
  }
  override def selectById(id: EmployeeId): ConnectionIO[Option[EmployeeRow]] = {
    sql"""select "id", "person_id", "salary" from "frontpage"."employee" where "id" = ${fromWrite(id)(new Write.Single(EmployeeId.put))}""".query(using EmployeeRow.read).option
  }
  override def selectByIds(ids: Array[EmployeeId]): Stream[ConnectionIO, EmployeeRow] = {
    sql"""select "id", "person_id", "salary" from "frontpage"."employee" where "id" = ANY(${ids})""".query(using EmployeeRow.read).stream
  }
  override def selectByIdsTracked(ids: Array[EmployeeId]): ConnectionIO[Map[EmployeeId, EmployeeRow]] = {
    selectByIds(ids).compile.toList.map { rows =>
      val byId = rows.view.map(x => (x.id, x)).toMap
      ids.view.flatMap(id => byId.get(id).map(x => (id, x))).toMap
    }
  }
  override def selectByUniquePersonId(personId: PersonId): ConnectionIO[Option[EmployeeRow]] = {
    sql"""select "id", "person_id", "salary"
          from "frontpage"."employee"
          where "person_id" = ${fromWrite(personId)(new Write.Single(PersonId.put))}
       """.query(using EmployeeRow.read).option
  }
  override def update: UpdateBuilder[EmployeeFields, EmployeeRow] = {
    UpdateBuilder(""""frontpage"."employee"""", EmployeeFields.structure, EmployeeRow.read)
  }
  override def update(row: EmployeeRow): ConnectionIO[Boolean] = {
    val id = row.id
    sql"""update "frontpage"."employee"
          set "person_id" = ${fromWrite(row.personId)(new Write.Single(PersonId.put))}::uuid,
              "salary" = ${fromWrite(row.salary)(new Write.SingleOpt(Meta.ScalaBigDecimalMeta.put))}::numeric
          where "id" = ${fromWrite(id)(new Write.Single(EmployeeId.put))}"""
      .update
      .run
      .map(_ > 0)
  }
  override def upsert(unsaved: EmployeeRow): ConnectionIO[EmployeeRow] = {
    sql"""insert into "frontpage"."employee"("id", "person_id", "salary")
          values (
            ${fromWrite(unsaved.id)(new Write.Single(EmployeeId.put))}::uuid,
            ${fromWrite(unsaved.personId)(new Write.Single(PersonId.put))}::uuid,
            ${fromWrite(unsaved.salary)(new Write.SingleOpt(Meta.ScalaBigDecimalMeta.put))}::numeric
          )
          on conflict ("id")
          do update set
            "person_id" = EXCLUDED."person_id",
            "salary" = EXCLUDED."salary"
          returning "id", "person_id", "salary"
       """.query(using EmployeeRow.read).unique
  }
  override def upsertBatch(unsaved: List[EmployeeRow]): Stream[ConnectionIO, EmployeeRow] = {
    Update[EmployeeRow](
      s"""insert into "frontpage"."employee"("id", "person_id", "salary")
          values (?::uuid,?::uuid,?::numeric)
          on conflict ("id")
          do update set
            "person_id" = EXCLUDED."person_id",
            "salary" = EXCLUDED."salary"
          returning "id", "person_id", "salary""""
    )(using EmployeeRow.write)
    .updateManyWithGeneratedKeys[EmployeeRow]("id", "person_id", "salary")(unsaved)(using catsStdInstancesForList, EmployeeRow.read)
  }
  /* NOTE: this functionality is not safe if you use auto-commit mode! it runs 3 SQL statements */
  override def upsertStreaming(unsaved: Stream[ConnectionIO, EmployeeRow], batchSize: Int = 10000): ConnectionIO[Int] = {
    for {
      _ <- sql"""create temporary table employee_TEMP (like "frontpage"."employee") on commit drop""".update.run
      _ <- new FragmentOps(sql"""copy employee_TEMP("id", "person_id", "salary") from stdin""").copyIn(unsaved, batchSize)(using EmployeeRow.text)
      res <- sql"""insert into "frontpage"."employee"("id", "person_id", "salary")
                   select * from employee_TEMP
                   on conflict ("id")
                   do update set
                     "person_id" = EXCLUDED."person_id",
                     "salary" = EXCLUDED."salary"
                   ;
                   drop table employee_TEMP;""".update.run
    } yield res
  }
}
